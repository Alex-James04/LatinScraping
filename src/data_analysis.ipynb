{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "181e70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5cb8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_parquet('../bin/scraped_latin_texts_words.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9833fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = base_df.copy()\n",
    "word_df = pd.DataFrame(word_df.groupby('word')['count'].sum()).reset_index()\n",
    "word_df['frequency'] = word_df['count'] / sum(word_df['count'])\n",
    "word_df['frequency_rank'] = word_df['count'].rank(method='max', ascending=False).astype(int)\n",
    "\n",
    "merge_df = base_df.copy()\n",
    "merge_df = pd.DataFrame(merge_df['word'].value_counts())\n",
    "merge_df['cross_text_count'] = merge_df['word']\n",
    "merge_df['word'] = merge_df.index\n",
    "merge_df = merge_df.reset_index().drop(columns='index')\n",
    "\n",
    "word_df = word_df.merge(merge_df, on='word', how='outer')\n",
    "\n",
    "word_df['cross_text_frequency'] = word_df['cross_text_count'] / len(base_df.groupby(['author', 'title'])['title'])\n",
    "\n",
    "\n",
    "merge_df = base_df.copy()\n",
    "merge_df = pd.DataFrame(merge_df.groupby(['author', 'word'])['count'].sum()).reset_index()\n",
    "merge_df = pd.DataFrame(merge_df['word'].value_counts())\n",
    "merge_df['cross_author_count'] = merge_df['word']\n",
    "merge_df['word'] = merge_df.index\n",
    "merge_df = merge_df.reset_index().drop(columns='index')\n",
    "\n",
    "word_df = word_df.merge(merge_df, on='word', how='outer')\n",
    "\n",
    "word_df['cross_author_frequency'] = word_df['cross_author_count'] / len(base_df['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8a7d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = base_df.copy()\n",
    "author_df = author_df.groupby(['author']).agg({'count': 'sum', 'word': 'nunique'}).rename(columns={'count': 'word_count', 'word': 'author_hapax_count'}).reset_index()\n",
    "\n",
    "base_df_copy = base_df.copy()\n",
    "author_word_pairs = base_df_copy[['author', 'word']].drop_duplicates()\n",
    "word_author_counts = author_word_pairs.groupby('word')['author'].nunique()\n",
    "unique_words = word_author_counts[word_author_counts == 1].index\n",
    "unique_author_words = author_word_pairs[author_word_pairs['word'].isin(unique_words)]\n",
    "merge_df = pd.DataFrame({'author': base_df['author'].unique()}).merge(unique_author_words.groupby('author').size().reset_index(name='cross_author_unique_word_count'), on='author', how='left')\n",
    "merge_df['cross_author_unique_word_count'] = merge_df['cross_author_unique_word_count'].fillna(0).astype(int)\n",
    "\n",
    "author_df = author_df.merge(merge_df, on='author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a60703f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = base_df.copy()\n",
    "text_df = text_df.groupby(['author', 'source', 'title']).agg({'count': 'sum', 'word': 'nunique'}).rename(columns={'count': 'word_count', 'word': 'text_hapax_count'}).reset_index().drop(columns=('source'))\n",
    "\n",
    "base_df_copy = base_df.copy()\n",
    "text_word_pairs = base_df_copy[['author', 'title', 'word']].drop_duplicates()\n",
    "text_word_counts = (text_word_pairs.groupby('word').apply(lambda x: x[['author', 'title']].drop_duplicates().shape[0]).reset_index(name='num_texts_using_word'))\n",
    "unique_words = text_word_counts[text_word_counts['num_texts_using_word'] == 1]['word']\n",
    "unique_text_words = text_word_pairs[text_word_pairs['word'].isin(unique_words)]\n",
    "merge_df = base_df_copy[['author', 'title']].drop_duplicates().merge(unique_text_words.groupby(['author', 'title']).size().reset_index(name='cross_text_unique_word_count'), on=['author', 'title'], how='left')\n",
    "merge_df['cross_text_unique_word_count'] = merge_df['cross_text_unique_word_count'].fillna(0).astype(int)\n",
    "\n",
    "text_df = text_df.merge(merge_df, on=['author', 'title'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6398f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export word_df as parquet to bin folder\n",
    "# word_df.to_parquet('../bin/scraped_latin_texts_word_data.parquet', index=False, compression=\"gzip\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export author_df as parquet to bin folder\n",
    "# author_df.to_parquet('../bin/scraped_latin_texts_author_data.parquet', index=False, compression=\"gzip\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export text_df as parquet to bin folder\n",
    "# text_df.to_parquet('../bin/scraped_latin_texts_text_data.parquet', index=False, compression=\"gzip\", engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
